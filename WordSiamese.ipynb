{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1757423d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b2d3911",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.4 | packaged by conda-forge | (main, Mar 30 2022, 08:38:02) [MSC v.1916 64 bit (AMD64)]\n",
      "python: 3.10.4 | packaged by conda-forge | (main, Mar 30 2022, 08:38:02) [MSC v.1916 64 bit (AMD64)]\n",
      "torch: 1.12.1\n",
      "torchvision: 0.13.1\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "\n",
    "import random\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from collections import defaultdict, namedtuple\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "import cv2\n",
    "\n",
    "import pickle\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "from path import Path\n",
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "\n",
    "print(sys.version)\n",
    "\n",
    "\n",
    "\n",
    "print('python: ' + str(sys.version))\n",
    "print('torch: ' + str(torch.__version__))\n",
    "print('torchvision: ' + str(torchvision.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1f57916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Paramaters\n",
    "iterations = 30000\n",
    "batch_size = 90 #90\n",
    "learning_rate = 0.0001 #0.00006\n",
    "way = 25\n",
    "caching = False\n",
    "modelPath = './wordsiamese/model/'\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.RandomAffine(15),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "net_input_size = (448, 448)\n",
    "net_output_size = (224, 224)\n",
    "data_dir = Path('./wordsiamese/data/')\n",
    "minimum_data_samples = 3 #minimum number of samples of a word for that word to be used 2 maybe 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "514d828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datasets and Loading\n",
    "\n",
    "class WordSet(Dataset):\n",
    "    def __init__(self, path, testing=False, transform = None, way=None, num_tests=None):\n",
    "        super(WordSet, self).__init__()\n",
    "        self.transform = transform\n",
    "        self.images, self.class_count = self.loadTTImages('./wordsiamese/data/croppedImages')\n",
    "        self.testing=testing\n",
    "        self.num_tests = num_tests\n",
    "        self.way = way\n",
    "        self.classA, self.imgA = None, None #allows for n-way learning\n",
    "        \n",
    "    def loadTTImages(self, path):\n",
    "        images = {} #stores all images loaded with identical character under one key\n",
    "        idCount = 0 #number of different character types\n",
    "        for word in os.listdir(path): #language character comes from\n",
    "            word = str(word)\n",
    "            images[word] = []\n",
    "            for individualTest in os.listdir(os.path.join(path, word)): #each character image\n",
    "                f_path = os.path.join(path, word, individualTest)\n",
    "                #images[idCount].append(Image.open(f_path))\n",
    "                images[word].append(f_path)\n",
    "                idCount += 1\n",
    "        return images, idCount\n",
    "    \n",
    "    def loadData(self, path):\n",
    "        images = {} #stores all images loaded with identical character under one key\n",
    "        idCount = 0 #number of different character types\n",
    "        \n",
    "        gt_dir = path / 'gt'\n",
    "        img_dir = path / 'img'\n",
    "        \n",
    "        for gt in sorted(gt_dir.files('*.xml')):\n",
    "            img = img_dir / gt.stem + '.png'\n",
    "            if not img.exists():\n",
    "                continue\n",
    "            \n",
    "            tree = ET.parse(gt)\n",
    "            root = tree.getroot()\n",
    "            \n",
    "            # go over all lines\n",
    "            for line in root.findall(\"./handwritten-part/line\"):\n",
    "\n",
    "                # go over all words\n",
    "                for word in line.findall('./word'):\n",
    "                    xmin, xmax, ymin, ymax = float('inf'), 0, float('inf'), 0\n",
    "                    success = False\n",
    "                    \n",
    "                    id_word = word.attrib['text'].lower()\n",
    "                    if id_word == '\\\"':\n",
    "                        id_word = 'double_quote_mark'\n",
    "                    elif id_word == '#':\n",
    "                        id_word = 'pound_mark'\n",
    "                    elif id_word == '&':\n",
    "                        id_word = 'ampersand'\n",
    "                    elif id_word == '{':\n",
    "                        id_word = 'left_curly_mark'\n",
    "                    elif id_word == '}':\n",
    "                        id_word = 'right_curly_mark'\n",
    "                    elif id_word == '*':\n",
    "                        id_word = 'asterisk_mark'\n",
    "                    elif id_word == '$':\n",
    "                        id_word = 'dollar_mark'\n",
    "                    elif id_word == '\\'':\n",
    "                        id_word = 'single_quote_mark'\n",
    "                    elif id_word == ':':\n",
    "                        id_word = 'colon_mark'\n",
    "                    elif id_word == '!':\n",
    "                        id_word = 'exclamation_mark'\n",
    "                    elif id_word == '?':\n",
    "                        id_word = 'question_mark'\n",
    "                    elif id_word == '.':\n",
    "                        id_word = 'period_mark'\n",
    "                    elif '.' in id_word or '\\\"' in id_word:\n",
    "                        continue\n",
    "                        \n",
    "                    # go over all characters\n",
    "                    for cmp in word.findall('./cmp'):\n",
    "                        success = True\n",
    "                        x = float(cmp.attrib['x'])\n",
    "                        y = float(cmp.attrib['y'])\n",
    "                        w = float(cmp.attrib['width'])\n",
    "                        h = float(cmp.attrib['height'])\n",
    "\n",
    "                        # aabb around all characters is aabb around word\n",
    "                        xmin = min(xmin, x)\n",
    "                        xmax = max(xmax, x + w)\n",
    "                        ymin = min(ymin, y)\n",
    "                        ymax = max(ymax, y + h)\n",
    "\n",
    "                    if success:\n",
    "                        if not id_word in images.keys():\n",
    "                            idCount += 1\n",
    "                            images[id_word] = []\n",
    "                        images[id_word].append(((xmin, ymin, xmax, ymax), img))\n",
    "        \n",
    "        remove = []\n",
    "        for key in images.keys():\n",
    "                if len(images[key]) < minimum_data_samples:\n",
    "                    remove.append(key)\n",
    "        \n",
    "        print(len(images.keys())-len(remove))\n",
    "        \n",
    "        for r in remove:\n",
    "            images.pop(r)\n",
    "            \n",
    "        self.images = images\n",
    "        return images, idCount\n",
    "    \n",
    "    def saveImages(self):\n",
    "        count = 0\n",
    "        print(len(self.images.keys()))\n",
    "        for key in self.images.keys():\n",
    "            count += 1\n",
    "            os.mkdir(f'./wordsiamese/data/croppedImages/{key}/')\n",
    "            i = 0\n",
    "            shuffled_key = random.sample(self.images[key], len(self.images[key]))\n",
    "            for img in shuffled_key:\n",
    "                \n",
    "                img_box = img[0]\n",
    "                img_img = img[1]\n",
    "\n",
    "                # Opens a image in RGB mode\n",
    "                img_img = Image.open(img_img)\n",
    "                img_crop = img_img.crop(img_box).convert('L').resize((105, 105))                \n",
    "                \n",
    "                \n",
    "                try:\n",
    "                    img_crop.save(f\"./wordsiamese/data/croppedImages/{key}/{i:04d}.jpg\")\n",
    "                except:\n",
    "                    print(count, key)\n",
    "                    print('saving exception failed due to complicated keys')\n",
    "                i += 1\n",
    "                if i > 20:\n",
    "                    break\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        label, imgA, imgB, idClassA, idClassB = None, None, None, None, None\n",
    "        \n",
    "        # i ensures that theres a mix of same and different sets\n",
    "        if self.testing:\n",
    "            if i % self.way == 0:\n",
    "                self.classA = random.choice(list(self.images.keys()))\n",
    "                self.imgA = random.choice(self.images[self.classA])\n",
    "                imgB = random.choice(self.images[self.classA])\n",
    "                while imgB == self.imgA:\n",
    "                    imgB = random.choice(self.images[self.classA])\n",
    "\n",
    "                \n",
    "                idClassA = self.classA\n",
    "                \n",
    "                print(f'Word: {idClassA}')\n",
    "\n",
    "            #different class\n",
    "            else:\n",
    "                idClassB = random.choice(list(self.images.keys()))#set B every time but A only n-way times\n",
    "                while self.classA == idClassB: #prevents same class\n",
    "                    idClassB = random.choice(list(self.images.keys()))\n",
    "                imgB = random.choice(self.images[idClassB])\n",
    "                \n",
    "                idClassA = self.classA\n",
    "                \n",
    "            imgA = self.imgA\n",
    "            \n",
    "            label = label = torch.from_numpy(np.array([-1.00], dtype=np.float32))\n",
    "            \n",
    "        else:\n",
    "            #same class\n",
    "            if i % 2 == 1:\n",
    "                label = torch.from_numpy(np.array([1.00], dtype=np.float32))\n",
    "                idClass = random.choice(list(self.images.keys()))\n",
    "                imgA, imgB = random.choice(self.images[idClass]), random.choice(self.images[idClass])\n",
    "                while imgB == imgA:\n",
    "                    imgB = random.choice(self.images[idClass])\n",
    "\n",
    "            #different class\n",
    "            else:\n",
    "                label = torch.from_numpy(np.array([0.00], dtype=np.float32))\n",
    "                idClassA, idClassB = random.choice(list(self.images.keys())), random.choice(list(self.images.keys()))\n",
    "                while idClassA == idClassB: #prevents same class\n",
    "                    idClassB = random.choice(list(self.images.keys()))\n",
    "                imgA = random.choice(self.images[idClassA])\n",
    "                imgB = random.choice(self.images[idClassB])\n",
    "    \n",
    "        \n",
    "        #print('a', imgA)\n",
    "        #print('b', imgB)\n",
    "        \n",
    "        # Opens a image in RGB mode\n",
    "        imgA = Image.open(imgA).convert('L')\n",
    "        imgB = Image.open(imgB).convert('L')\n",
    "        \n",
    "        \n",
    "        \n",
    "        #print(f'Img A: {idClassA}')\n",
    "        #plt.imshow(imgA)\n",
    "        #plt.show()\n",
    "        #print(f'Img B: {idClassB}')\n",
    "        #plt.imshow(imgB)\n",
    "        #plt.show()\n",
    "        \n",
    "\n",
    "        # create figure\n",
    "        fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "        # setting values to rows and column variables\n",
    "        rows = 2\n",
    "        columns = 2\n",
    "\n",
    "        # Adds a subplot at the 1st position\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "\n",
    "        # showing image\n",
    "        plt.imshow(Image1)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"First\")\n",
    "\n",
    "        # Adds a subplot at the 2nd position\n",
    "        fig.add_subplot(rows, columns, 2)\n",
    "\n",
    "        # showing image\n",
    "        plt.imshow(Image2)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Second\")\n",
    "\n",
    "        # Adds a subplot at the 3rd position\n",
    "        fig.add_subplot(rows, columns, 3)\n",
    "\n",
    "        # showing image\n",
    "        plt.imshow(Image3)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Third\")\n",
    "\n",
    "        # Adds a subplot at the 4th position\n",
    "        fig.add_subplot(rows, columns, 4)\n",
    "\n",
    "        # showing image\n",
    "        plt.imshow(Image4)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Fourth\")\n",
    "        \n",
    "        imgA = self.transform(imgA)\n",
    "        imgB = self.transform(imgB)\n",
    "        \n",
    "        \n",
    "        return imgA, imgB, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.testing:\n",
    "            return self.num_tests * self.way\n",
    "        else:\n",
    "            return  21000000 #5250000\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e3fd8066",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data preperations\n",
    "\n",
    "trainSet = WordSet(data_dir, transform=data_transforms)\n",
    "#trainSet.loadData(data_dir)\n",
    "#trainSet.saveImages()\n",
    "testSet = WordSet(data_dir, transform=transforms.ToTensor(), testing=True, num_tests = 400, way = way)\n",
    "\n",
    "trainLoader = DataLoader(trainSet, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "testLoader = DataLoader(testSet, batch_size=way, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07f57e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 - NVIDIA GeForce GTX 1650 SUPER\n"
     ]
    }
   ],
   "source": [
    "#Check GPU\n",
    "device = torch.device(\"cuda:\" + str(torch.cuda.current_device()) if torch.cuda.is_available() else \"cpu\")\n",
    "print((str(device) + \" - \" + str(torch.cuda.get_device_name(torch.cuda.current_device()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6afc0908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Siamese(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(10, 10), stride=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 128, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Conv2d(128, 256, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (10): ReLU()\n",
      "  )\n",
      "  (liner): Sequential(\n",
      "    (0): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      "  (out): Linear(in_features=4096, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Siamese Model\n",
    "class Siamese(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Siamese, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 10),  # 64@96*96\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 64@48*48\n",
    "            nn.Conv2d(64, 128, 7),\n",
    "            nn.ReLU(),    # 128@42*42\n",
    "            nn.MaxPool2d(2),   # 128@21*21\n",
    "            nn.Conv2d(128, 128, 4),\n",
    "            nn.ReLU(), # 128@18*18\n",
    "            nn.MaxPool2d(2), # 128@9*9\n",
    "            nn.Conv2d(128, 256, 4),\n",
    "            nn.ReLU(),   # 256@6*6\n",
    "        )\n",
    "        self.liner = nn.Sequential(nn.Linear(9216, 4096), nn.Sigmoid())\n",
    "        self.out = nn.Linear(4096, 1)\n",
    "        \n",
    "    def forward_one(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.liner(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        out1 = self.forward_one(x1)\n",
    "        out2 = self.forward_one(x2)\n",
    "        dis = torch.abs(out1 - out2)\n",
    "        out = self.out(dis)\n",
    "        #return self.sigmoid(out)\n",
    "        return out\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    net = Siamese()\n",
    "    print(net)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c1c079",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train\n",
    "\n",
    "print('initializing training')\n",
    "\n",
    "loss_function = torch.nn.BCEWithLogitsLoss()#default for size average is true\n",
    "loss_value = 0\n",
    "loss_values = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "accuracies = []\n",
    "a_assist = []\n",
    "\n",
    "checkpoint = torch.load('./wordsiamese/model/training-model-26400.pt')\n",
    "\n",
    "network = Siamese() #creates a new network\n",
    "network.load_state_dict(checkpoint['model_state_dict'])\n",
    "network.to(device)\n",
    "network.train() #sets the mode of the network to training\n",
    "\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr = learning_rate)\n",
    "optimizer.zero_grad() #zeros out the gradients\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "\n",
    "cepoch = int(checkpoint['epoch'])\n",
    "\n",
    "checkpoint = None\n",
    "\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "initial_start_time = start_time\n",
    "print('starting training loop')\n",
    "for i, (imgA, imgB, label) in enumerate(trainLoader, start=1):\n",
    "    if i + cepoch > iterations:\n",
    "        break\n",
    "    \n",
    "    imgA = Variable(imgA.cuda())\n",
    "    imgB = Variable(imgB.cuda())\n",
    "    label = Variable(label.cuda())\n",
    "    \n",
    "    optimizer.zero_grad() #zeros out the gradients since paramaters already updated with old gradient\n",
    "    \n",
    "    output = network.forward(imgA, imgB) #gets similarity probability\n",
    "    \n",
    "    loss = loss_function(output, label)\n",
    "    \n",
    "    li = loss.item()\n",
    "    \n",
    "    loss_value += li\n",
    "    loss_values.append(li)\n",
    "    loss.backward() #computes the gradient of loss for all parameters\n",
    "    \n",
    "    optimizer.step() #updates parameters\n",
    "    \n",
    "    #print updates for the user\n",
    "    if i % 10 == 0:\n",
    "        print(f'{i + cepoch} loss: {loss_value/10} time elapsed: {time.time()-start_time}')\n",
    "        loss_value = 0\n",
    "        start_time = time.time()\n",
    "        if i % 100 == 0:\n",
    "            correct, wrong = 0, 0\n",
    "            for _, (testA, testB, _) in enumerate(testLoader, 1):\n",
    "                testA, testB = Variable(testA.cuda()), Variable(testB.cuda())\n",
    "                output = network.forward(testA, testB).data.cpu().numpy() #computes the probability\n",
    "                prediction = np.argmax(output) #gets the index of highest value in output\n",
    "                if prediction == 0:\n",
    "                    correct += 1\n",
    "                else:\n",
    "                    wrong += 1\n",
    "\n",
    "            print('-'*100)\n",
    "            print(f'{i + cepoch} Testing Set Correct: {correct} Wrong: {wrong} Precision: {correct*1.0/(correct + wrong)}')\n",
    "            print('-'*100)\n",
    "            accuracies.append(correct*1.0/(correct+wrong))\n",
    "            a_assist.append(i)\n",
    "            if i % 300 == 0:\n",
    "                print('saving...')\n",
    "                torch.save({\n",
    "                    'epoch': i + cepoch,\n",
    "                    'model_state_dict': network.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss_value,\n",
    "                    }, f'{modelPath}training-model-{i + cepoch}.pt')\n",
    "\n",
    "\n",
    "print('finish training loop, time elapsed: ', str(time.time()-initial_start_time))\n",
    "    \n",
    "#add final accuracies\n",
    "accuracy = 0.0\n",
    "counter = 0\n",
    "for d in accuracies:\n",
    "    print(d)\n",
    "    accuracy += d\n",
    "    counter += 1\n",
    "print(\"#\"*100)\n",
    "print(\"final accuracy: \", accuracy/counter)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc7bb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define subplots\n",
    "fig, ax = plt.subplots(2, 1, figsize=(15,20))\n",
    "#fig.tight_layout()\n",
    "\n",
    "#create subplots\n",
    "ax[0].plot(range(1, iterations + 1), loss_values, color='red')\n",
    "ax[0].set_title('Loss Values During Training')\n",
    "ax[0].set_ylabel('Loss Value')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[1].plot(a_assist, accuracies, color='blue')\n",
    "ax[1].set_title('Accuracies During Training')\n",
    "ax[1].set_ylabel('Accuracies')\n",
    "ax[1].set_xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fe77e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Test Image Loading\n",
    "imgT=mpimg.imread('./wordsiamese/data/img/a01-000u.png')\n",
    "plt.imshow(imgT)\n",
    "\n",
    "im = Image.open('./wordsiamese/data/img/a01-000u.png')\n",
    " \n",
    "newsize = (800, 300)\n",
    "im1 = im.resize\n",
    "# Shows the image in image viewer\n",
    "im.show()\n",
    "im1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "329689e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin testing\n",
      "Test: 0\n",
      "Word: sum\n",
      "Prediction: 20\n",
      "Test: 1\n",
      "picking new\n",
      "Word: target\n",
      "Prediction: 0\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('./wordsiamese/model/training-model-26100.pt')\n",
    "\n",
    "network = Siamese() #creates a new network\n",
    "network.load_state_dict(checkpoint['model_state_dict'])\n",
    "network.to(device)\n",
    "network.eval() #sets the mode of the network to training\n",
    "\n",
    "print('begin testing')\n",
    "counter = 0\n",
    "print(f'Test: {counter}')\n",
    "for _, (testA, testB, _) in enumerate(testLoader, 1):\n",
    "        counter += 1\n",
    "        testA, testB = Variable(testA.cuda()), Variable(testB.cuda())\n",
    "        output = network.forward(testA, testB).data.cpu().numpy() #computes the probability\n",
    "        #print(output)\n",
    "        prediction = np.argmax(output) #gets the index of highest value in output\n",
    "        print(f'Prediction: {prediction}')\n",
    "        if counter > 1:\n",
    "            break\n",
    "        print(f'Test: {counter}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:research]",
   "language": "python",
   "name": "conda-env-research-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
